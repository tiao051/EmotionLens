import os
import numpy as np
import librosa
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
from sklearn.utils.class_weight import compute_class_weight
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import (Input, Conv1D, MaxPooling1D, Dropout,
                                   BatchNormalization, LSTM, Bidirectional,
                                   Dense, LayerNormalization, Add,
                                   MultiHeadAttention, GlobalAveragePooling1D)
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.regularizers import l2
from tensorflow.keras.losses import CategoricalCrossentropy


class AudioFeatureExtractor:
    def __init__(self, n_mfcc=80, max_len=400):
        self.n_mfcc = n_mfcc
        self.max_len = max_len
    
    def extract_mfcc_from_file(self, file_path, augment=False):
        # ƒê·ªçc file √¢m thanh
        y, sr = librosa.load(file_path, sr=None)
        
        # Th·ª±c hi·ªán data augmentation n·∫øu c·∫ßn
        if augment:
            y = self._random_augment(y, sr)
        
        # Tr√≠ch xu·∫•t MFCC
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=self.n_mfcc)
        
        # Chu·∫©n h√≥a k√≠ch th∆∞·ªõc
        if mfcc.shape[1] < self.max_len:
            # Pad n·∫øu file qu√° ng·∫Øn
            pad_width = self.max_len - mfcc.shape[1]
            mfcc = np.pad(mfcc, ((0,0),(0,pad_width)), mode='constant')
        else:
            # C·∫Øt n·∫øu file qu√° d√†i
            mfcc = mfcc[:, :self.max_len]
        
        # Chuy·ªÉn v·ªã ma tr·∫≠n cho ƒë·ªãnh d·∫°ng ƒë·∫ßu v√†o LSTM v√† normalize
        mfcc = mfcc.T  # shape: (max_len, n_mfcc)
        
        # Chu·∫©n h√≥a: tr·ª´ mean, chia std theo t·ª´ng file
        mean = np.mean(mfcc, axis=0, keepdims=True)
        std = np.std(mfcc, axis=0, keepdims=True) + 1e-8
        mfcc_norm = (mfcc - mean) / std
        
        return mfcc_norm
    
    def _augment_speed(self, y, rate=None):
        import random
        if rate is None:
            rate = random.uniform(0.9, 1.1)
        return librosa.effects.time_stretch(y, rate)

    def _augment_pitch(self, y, sr, n_steps=None):
        import random
        if n_steps is None:
            n_steps = random.randint(-2, 2)
        return librosa.effects.pitch_shift(y, sr, n_steps=n_steps)

    def _augment_noise(self, y, noise_level=None):
        import random
        if noise_level is None:
            noise_level = random.uniform(0.001, 0.01)
        noise = np.random.randn(len(y))
        return y + noise_level * noise

    def _random_augment(self, y, sr):
        import random
        # X√°c su·∫•t m·ªói augmentation ~50%
        if random.random() < 0.5:
            y = self._augment_speed(y)
        if random.random() < 0.5:
            y = self._augment_pitch(y, sr)
        if random.random() < 0.5:
            y = self._augment_noise(y)
        return y


class EmotionDataProcessor:
    def __init__(self, feature_extractor=None, emotions=None):
        if feature_extractor is None:
            self.feature_extractor = AudioFeatureExtractor()
        else:
            self.feature_extractor = feature_extractor
            
        if emotions is None:
            self.emotions = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad']
        else:
            self.emotions = emotions
            
        self.label_encoder = LabelEncoder()
    
    def extract_features_from_directory(self, audio_root, output_features=None, output_labels=None):
        import tqdm
        features = []
        labels = []

        for emotion in self.emotions:
            emotion_dir = os.path.join(audio_root, emotion)
            if not os.path.exists(emotion_dir):
                continue
                
            files = [f for f in os.listdir(emotion_dir) if f.endswith('.wav') or f.endswith('.mp3')]
            
            for f in tqdm.tqdm(files, desc=f"Extracting {emotion}"):
                file_path = os.path.join(emotion_dir, f)
                try:
                    # ƒê·∫∑c tr∆∞ng g·ªëc
                    mfcc_seq = self.feature_extractor.extract_mfcc_from_file(file_path)
                    features.append(mfcc_seq)
                    labels.append(emotion)
                    
                    # Augmentation 1
                    mfcc_aug1 = self.feature_extractor.extract_mfcc_from_file(file_path, augment=True)
                    features.append(mfcc_aug1)
                    labels.append(emotion)
                    
                    # C√≥ th·ªÉ th√™m augmentation 2, 3... n·∫øu mu·ªën
                except Exception as e:
                    print(f"Error processing {file_path}: {e}")
        
        features = np.array(features)  # shape: (num_samples, max_len, n_mfcc)
        labels = np.array(labels)
        
        # L∆∞u file n·∫øu c√≥ ch·ªâ ƒë·ªãnh ƒë∆∞·ªùng d·∫´n
        if output_features is not None:
            np.save(output_features, features)
            
        if output_labels is not None:
            np.save(output_labels, labels)
            
        print(f"Done! Extracted {len(features)} samples with shape {features.shape}")
        return features, labels
    
    def prepare_training_data(self, features, labels, test_size=0.2, random_state=42):
        # M√£ h√≥a nh√£n
        y_encoded = self.label_encoder.fit_transform(labels)
        y_cat = to_categorical(y_encoded)
        
        # Chia d·ªØ li·ªáu
        X_train, X_test, y_train, y_test = train_test_split(
            features, y_cat, test_size=test_size, stratify=y_cat, random_state=random_state
        )
        
        # T√≠nh class weights
        y_flat = np.argmax(y_cat, axis=1)
        class_weights = compute_class_weight('balanced', classes=np.unique(y_flat), y=y_flat)
        class_weight_dict = dict(enumerate(class_weights))
        
        return X_train, X_test, y_train, y_test, class_weight_dict


class EmotionRecognitionModel:
    def __init__(self, input_shape=None, num_classes=6):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.model = None
        self.history = None
        
    def build_bilstm_mha_model(self):
        """
        X√¢y d·ª±ng m√¥ h√¨nh BiLSTM k·∫øt h·ª£p v·ªõi Multi-Head Attention
        
        Returns:
            Model: M√¥ h√¨nh ƒë√£ x√¢y d·ª±ng
        """
        if self.input_shape is None:
            raise ValueError("input_shape must be specified")
            
        # ƒê·∫ßu v√†o
        inp = Input(shape=self.input_shape)
        
        # Kh·ªëi t√≠ch ch·∫≠p 1
        x = Conv1D(64, kernel_size=5, activation='relu', padding='same', kernel_regularizer=l2(1e-4))(inp)
        x = BatchNormalization()(x)
        x = MaxPooling1D(pool_size=2)(x)
        x = Dropout(0.15)(x)
        
        # Kh·ªëi t√≠ch ch·∫≠p 2
        x = Conv1D(128, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(1e-4))(x)
        x = BatchNormalization()(x)
        x = MaxPooling1D(pool_size=2)(x)
        x = Dropout(0.2)(x)
        
        # Kh·ªëi BiLSTM
        x = Bidirectional(LSTM(64, return_sequences=True))(x)
        x = Dropout(0.2)(x)
        
        # Kh·ªëi Multi-Head Attention
        attn = MultiHeadAttention(num_heads=4, key_dim=64)(x, x)
        x = Add()([x, attn])
        x = LayerNormalization()(x)
        
        # Global Pooling
        x = GlobalAveragePooling1D()(x)
        
        # Kh·ªëi Fully Connected
        x = Dense(64, activation='relu', kernel_regularizer=l2(1e-4))(x)
        x = Dropout(0.3)(x)
        x = Dense(32, activation='relu', kernel_regularizer=l2(1e-4))(x)
        x = Dropout(0.2)(x)
        
        # Output layer
        output = Dense(self.num_classes, activation='softmax')(x)
        
        # T·∫°o m√¥ h√¨nh
        self.model = Model(inputs=inp, outputs=output)
        
        # Bi√™n d·ªãch m√¥ h√¨nh
        self.model.compile(
            optimizer='adam',
            loss=CategoricalCrossentropy(label_smoothing=0.1),
            metrics=['accuracy']
        )
        
        return self.model
    
    def train(self, X_train, y_train, X_test, y_test, class_weight_dict=None, 
              epochs=60, batch_size=32, patience=6):
        """
        Hu·∫•n luy·ªán m√¥ h√¨nh
        
        Args:
            X_train (np.ndarray): D·ªØ li·ªáu hu·∫•n luy·ªán
            y_train (np.ndarray): Nh√£n hu·∫•n luy·ªán
            X_test (np.ndarray): D·ªØ li·ªáu ki·ªÉm tra
            y_test (np.ndarray): Nh√£n ki·ªÉm tra
            class_weight_dict (dict): Tr·ªçng s·ªë cho c√°c l·ªõp
            epochs (int): S·ªë epoch t·ªëi ƒëa
            batch_size (int): K√≠ch th∆∞·ªõc batch
            patience (int): S·ªë epoch t·ªëi ƒëa kh√¥ng c·∫£i thi·ªán
            
        Returns:
            History: L·ªãch s·ª≠ hu·∫•n luy·ªán
        """
        # Ki·ªÉm tra m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c x√¢y d·ª±ng ch∆∞a
        if self.model is None:
            if self.input_shape is None:
                self.input_shape = X_train.shape[1:]
                self.num_classes = y_train.shape[1]
            self.build_bilstm_mha_model()
        
        # Callbacks
        early_stop = EarlyStopping(
            monitor='val_accuracy',
            patience=patience,
            restore_best_weights=True,
            mode='max'
        )
        
        reduce_lr = ReduceLROnPlateau(
            monitor='val_accuracy',
            factor=0.5,
            patience=2,
            min_lr=1e-6,
            mode='max'
        )
        
        # Hu·∫•n luy·ªán m√¥ h√¨nh
        self.history = self.model.fit(
            X_train, y_train,
            epochs=epochs,
            batch_size=batch_size,
            validation_data=(X_test, y_test),
            callbacks=[early_stop, reduce_lr],
            class_weight=class_weight_dict
        )
        
        return self.history
    
    def evaluate(self, X_test, y_test, label_names=None):
        """
        ƒê√°nh gi√° m√¥ h√¨nh
        
        Args:
            X_test (np.ndarray): D·ªØ li·ªáu ki·ªÉm tra
            y_test (np.ndarray): Nh√£n ki·ªÉm tra (one-hot encoding)
            label_names (list): T√™n c√°c l·ªõp
            
        Returns:
            tuple: (loss, accuracy, report) - ƒê·ªô l·ªói, ƒë·ªô ch√≠nh x√°c v√† b√°o c√°o ph√¢n lo·∫°i chi ti·∫øt
        """
        # ƒê√°nh gi√°
        loss, acc = self.model.evaluate(X_test, y_test)
        print(f"\nüéØ Test accuracy: {acc:.2%}")
        
        # D·ª± ƒëo√°n v√† so s√°nh
        y_pred = np.argmax(self.model.predict(X_test), axis=1)
        y_true = np.argmax(y_test, axis=1)
        
        # B√°o c√°o ph√¢n lo·∫°i
        report = classification_report(y_true, y_pred, target_names=label_names, output_dict=True)
        print("\nüìä Classification report:\n")
        print(classification_report(y_true, y_pred, target_names=label_names))
        
        return loss, acc, report
    
    def save_model(self, model_path):
        """
        L∆∞u m√¥ h√¨nh
        
        Args:
            model_path (str): ƒê∆∞·ªùng d·∫´n l∆∞u m√¥ h√¨nh
        """
        if self.model is None:
            raise ValueError("Model has not been built or trained")
            
        self.model.save(model_path)
        print(f"‚úÖ Model saved to {model_path}")
    
    def load_model(self, model_path):
        """
        T·∫£i m√¥ h√¨nh ƒë√£ l∆∞u
        
        Args:
            model_path (str): ƒê∆∞·ªùng d·∫´n t·ªõi m√¥ h√¨nh
            
        Returns:
            Model: M√¥ h√¨nh ƒë√£ t·∫£i
        """
        self.model = load_model(model_path)
        return self.model
    
    def predict(self, features):
        """
        D·ª± ƒëo√°n c·∫£m x√∫c t·ª´ ƒë·∫∑c tr∆∞ng
        
        Args:
            features (np.ndarray): ƒê·∫∑c tr∆∞ng MFCC ƒë√£ chu·∫©n h√≥a
            
        Returns:
            np.ndarray: X√°c su·∫•t c√°c l·ªõp c·∫£m x√∫c
        """
        if self.model is None:
            raise ValueError("Model has not been built or loaded")
            
        # Ensure features have the right shape (add batch dimension if needed)
        if len(features.shape) == 2:
            features = np.expand_dims(features, axis=0)
            
        return self.model.predict(features)
    
    def plot_training_history(self, save_path=None):
        """
        V·∫Ω bi·ªÉu ƒë·ªì l·ªãch s·ª≠ hu·∫•n luy·ªán
        
        Args:
            save_path (str, optional): ƒê∆∞·ªùng d·∫´n l∆∞u bi·ªÉu ƒë·ªì
        """
        if self.history is None:
            raise ValueError("Model has not been trained")
            
        plt.figure(figsize=(12, 5))
        
        # ƒê·ªì th·ªã loss
        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['loss'], label='Train loss')
        plt.plot(self.history.history['val_loss'], label='Val loss')
        plt.title('Loss per Epoch')
        plt.legend()
        
        # ƒê·ªì th·ªã accuracy
        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['accuracy'], label='Train acc')
        plt.plot(self.history.history['val_accuracy'], label='Val acc')
        plt.title('Accuracy per Epoch')
        plt.legend()
        
        plt.tight_layout()
        
        if save_path is not None:
            plt.savefig(save_path)
            print(f"‚úÖ Training history plot saved to {save_path}")
            
        plt.show()


class EmotionPredictorApp:
    """
    L·ªõp ·ª©ng d·ª•ng d·ª± ƒëo√°n c·∫£m x√∫c
    """
    def __init__(self, model_path, labels_path):
        """
        Kh·ªüi t·∫°o ·ª©ng d·ª•ng d·ª± ƒëo√°n c·∫£m x√∫c
        
        Args:
            model_path (str): ƒê∆∞·ªùng d·∫´n t·ªõi m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
            labels_path (str): ƒê∆∞·ªùng d·∫´n t·ªõi file nh√£n
        """
        # T·∫°o tr√¨nh tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng
        self.feature_extractor = AudioFeatureExtractor()
        
        # T·∫£i m√¥ h√¨nh
        self.model = EmotionRecognitionModel()
        self.model.load_model(model_path)
        
        # T·∫°o v√† hu·∫•n luy·ªán LabelEncoder
        self.labels = np.load(labels_path)
        self.label_encoder = LabelEncoder()
        self.label_encoder.fit(self.labels)
    
    def predict_from_file(self, audio_path):
        """
        D·ª± ƒëo√°n c·∫£m x√∫c t·ª´ file √¢m thanh
        
        Args:
            audio_path (str): ƒê∆∞·ªùng d·∫´n t·ªõi file √¢m thanh
            
        Returns:
            tuple: (emotion, probs) - C·∫£m x√∫c d·ª± ƒëo√°n v√† x√°c su·∫•t c√°c l·ªõp
        """
        # Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng
        features = self.feature_extractor.extract_mfcc_from_file(audio_path)
        
        # D·ª± ƒëo√°n
        probs = self.model.predict(features)[0]
        
        # L·∫•y class c√≥ x√°c su·∫•t cao nh·∫•t
        pred_idx = np.argmax(probs)
        
        # Chuy·ªÉn ƒë·ªïi t·ª´ index v·ªÅ nh√£n c·∫£m x√∫c
        emotion = self.label_encoder.inverse_transform([pred_idx])[0]
        
        return emotion, probs
    
    def run_gui(self):
        """
        Ch·∫°y giao di·ªán ng∆∞·ªùi d√πng ƒë∆°n gi·∫£n
        """
        import tkinter as tk
        from tkinter import filedialog, messagebox
        
        # Kh·ªüi t·∫°o giao di·ªán
        root = tk.Tk()
        root.withdraw()
        
        # Hi·ªÉn th·ªã h·ªôp tho·∫°i ch·ªçn file
        file_path = filedialog.askopenfilename(
            title="Ch·ªçn file audio ƒë·ªÉ ph√¢n t√≠ch c·∫£m x√∫c",
            filetypes=[("Audio files", "*.wav *.mp3")]
        )
        
        if not file_path:
            print("Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c ch·ªçn.")
            return
            
        try:
            # D·ª± ƒëo√°n c·∫£m x√∫c
            emotion, probs = self.predict_from_file(file_path)
            
            # T·∫°o n·ªôi dung th√¥ng b√°o k·∫øt qu·∫£
            msg = f"D·ª± ƒëo√°n c·∫£m x√∫c: {emotion}\n\nX√°c su·∫•t t·ª´ng l·ªõp:\n"
            for i, label in enumerate(self.label_encoder.classes_):
                msg += f"{label}: {probs[i]:.2%}\n"
                
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            messagebox.showinfo("K·∫øt qu·∫£ ph√¢n t√≠ch c·∫£m x√∫c", msg)
            print(msg)
        except Exception as e:
            messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ ph√¢n t√≠ch file n√†y!\n{e}")
            print(f"L·ªói: {e}")
